# Ames-Housing-Price-Prediction (Top 4% for Kaggle Competition)
This project when I become in the [top 4%](https://www.kaggle.com/malikafuhamid/competitions) in Kaggle Competition.
Top 4% – Housing Price Competition for Kaggle Learn Users

I entered this competition to practice my skill in making a machine learning model. The dataset in the competition involved a1460 rows and 80 columns. And this is what I do:

• Developed several models of machine learning algorithms such as XGBoost, LGBM, Random Forest, and ElasticNet to predict the final price of each house
• Applied a feature engineering with binning feature and reduce the dimension with mean score decrease to get better information on data
• Use several techniques of encoding such as OneHotEncoder, BinaryEncoder, and OrdinalEncoder
• Improve the model with RandomizedSearch to tune parameters such as max_depth, learning_rate, n_estimators, subsample, gamma, colsample_bytree, reg_alpha, and reg_lambda 
• Gaining the best score around 92.8% in XGBoost without overfitting
